{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "from scipy.misc import imsave\n",
    "\n",
    "from tensorflow.spectral import dct, idct\n",
    "from scipy.fftpack import dct as DCT, idct as IDCT\n",
    "from tensorflow.keras.backend import eval\n",
    "import skimage.measure as metrics\n",
    "\n",
    "# Importing our U-Net model\n",
    "MY_UTILS_PATH = \"../../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "from models import unet_old, unet, my_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct2d(im):\n",
    "    return DCT(DCT(im,type=2,axis=0,norm='ortho'),type=2,axis=1,norm='ortho')\n",
    "def idct2d(mat):\n",
    "    return IDCT(IDCT(mat,type=2,axis=0,norm='ortho'),type=2,axis=1,norm='ortho')\n",
    "\n",
    "def dct_in_blocks(im, block_size = 8):\n",
    "\n",
    "    rows, cols = im.shape[0], im.shape[1]\n",
    "\n",
    "    # block size: 8x8\n",
    "    if rows % block_size == cols % block_size == 0:\n",
    "        blocks_count = rows // block_size * cols // block_size\n",
    "    else:\n",
    "        raise ValueError((\"the width and height of the image \"\n",
    "                          \"should both be mutiples of %block_size\"))\n",
    "\n",
    "    dct_matrix = np.zeros((rows, cols))\n",
    "\n",
    "    for i in range(0, rows, block_size):\n",
    "        for j in range(0, cols, block_size):\n",
    "\n",
    "            block = im[i:i+block_size, j:j+block_size]\n",
    "            dct_matrix[i:i+block_size,j:j+block_size] = dct2d(block)\n",
    "\n",
    "    return dct_matrix\n",
    "\n",
    "def idct_in_blocks(dct_mat, block_size = 8):\n",
    "\n",
    "    rows, cols = dct_mat.shape[0], dct_mat.shape[1]\n",
    "\n",
    "    # block size: 8x8\n",
    "    if rows % block_size == cols % block_size == 0:\n",
    "        blocks_count = rows // block_size * cols // block_size\n",
    "    else:\n",
    "        raise ValueError((\"the width and height of the image \"\n",
    "                          \"should both be mutiples of %block_size\"))\n",
    "\n",
    "    im_matrix = np.zeros((rows, cols))\n",
    "\n",
    "    for i in range(0, rows, block_size):\n",
    "        for j in range(0, cols, block_size):\n",
    "\n",
    "            block = dct_mat[i:i+block_size, j:j+block_size]\n",
    "            im_matrix[i:i+block_size,j:j+block_size] = idct2d(block)\n",
    "\n",
    "    return im_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 10740\n",
      "Validation set size: 5370\n",
      "Test set size: 16110\n"
     ]
    }
   ],
   "source": [
    "# Train and validation data paths\n",
    "train_path = \"/home/ubuntu/volume1/TIFF/Development/Training/*.tif\"\n",
    "val_path = \"/home/ubuntu/volume1/TIFF/Development/Validation/*.tif\"\n",
    "test_path = \"/home/ubuntu/volume1/TIFF/Testing/*.tif\"\n",
    "\n",
    "\n",
    "# Listing train and validation images\n",
    "train_images = sorted(glob.glob(train_path))\n",
    "val_images = sorted(glob.glob(val_path))\n",
    "test_images = sorted(glob.glob(test_path))\n",
    "\n",
    "# Summary of images\n",
    "print(\"Train set size:\", len(train_images))\n",
    "print(\"Validation set size:\",len(val_images))\n",
    "print(\"Test set size:\",len(test_images))\n",
    "\n",
    "# images_path = \"../../../Gray/*.tif\"\n",
    "# images = glob.glob(images_path)\n",
    "# print(len(images))\n",
    "# # Listing train and validation images\n",
    "# train_images = images[0:30000]\n",
    "# val_images = images[30000:45000]\n",
    "# test_images = images[45000:]\n",
    "\n",
    "# # Summary of images\n",
    "# print(\"Train set size:\", len(train_images))\n",
    "# print(\"Validation set size:\",len(val_images))\n",
    "# print(\"Test set size:\",len(test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 256, 256\n",
    "norm = 255.0\n",
    "compr_range = (10,20)\n",
    "\n",
    "test_unc = np.zeros((len(test_images),H,W,1), dtype=np.float32)\n",
    "test_compr = test_unc.copy()\n",
    "\n",
    "dct_test_unc = test_unc.copy()\n",
    "dct_test_compr = test_unc.copy()\n",
    "\n",
    "compr_test = np.random.choice(np.arange(compr_range[0],compr_range[1], dtype=int), \\\n",
    "                               len(test_images),replace = True)\n",
    "\n",
    "# Test set\n",
    "for ii in range(len(test_images)):\n",
    "    # Load uncompressed image\n",
    "    im1 = Image.open(test_images[ii])\n",
    "    test_unc[ii,:,:,0] = np.array(im1, dtype=np.float32)\n",
    "\n",
    "    # JPEG compress the image    \n",
    "    buf = io.BytesIO()\n",
    "    im1.save(buf, \"JPEG\", quality=int(compr_test[ii]))\n",
    "    im2 = Image.open(buf)\n",
    "    test_compr[ii,:,:,0] = np.array(im2, dtype=np.float32)\n",
    "\n",
    "test_unc -= 128.0\n",
    "test_compr -= 128.0\n",
    "\n",
    "test_unc /= 128.0\n",
    "test_compr /= 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "useBlocks = True\n",
    "\n",
    "if useBlocks:\n",
    "    for ii in range(len(test_images)):\n",
    "        dct_test_compr[ii,:,:,0] = dct_in_blocks(test_compr[ii,:,:,0])\n",
    "else:\n",
    "    for ii in range(len(test_images)):\n",
    "        dct_test_compr[ii,:,:,0] = dct2d(test_compr[ii,:,:,0])\n",
    "    \n",
    "# # keep min/max values to de-normalize later\n",
    "# dct_test_compr_min = np.zeros(len(test_images))\n",
    "# dct_test_compr_max = np.zeros(len(test_images))\n",
    "\n",
    "# for ii in range(len(test_images)):\n",
    "#     dct_test_compr_min[ii] = np.min(dct_test_compr[ii,:,:,0])\n",
    "#     dct_test_compr_max[ii] = np.max(dct_test_compr[ii,:,:,0])\n",
    "\n",
    "# print(dct_test_compr_min.shape)\n",
    "# print(dct_test_compr_max.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(lr=0.0001)\n",
    "model_name = \"../../Models/residual_unet_DCT_data_augmentation_compress_10_20_2019-03-25-pretrained.hdf5\"\n",
    "#model = unet_old(input_size = (256 ,256 ,1),drop = 0.0,residual = True)\n",
    "model=my_unet()\n",
    "model.compile(loss = \"mse\",optimizer=opt)\n",
    "\n",
    "model.load_weights(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(dct_test_compr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred = test_unc.copy()\n",
    "\n",
    "test_unc *= 128.0\n",
    "test_unc += 128.0\n",
    "\n",
    "test_compr *= 128.0\n",
    "test_compr += 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useBlocks:\n",
    "    for ii in range(len(test_images)):\n",
    "        img_pred[ii,:,:,0] = idct_in_blocks(pred[ii,:,:,0])\n",
    "else:\n",
    "    for ii in range(len(test_images)):\n",
    "        img_pred[ii,:,:,0] = idct2d(pred[ii,:,:,0])\n",
    "        \n",
    "img_pred *= 128.0\n",
    "img_pred += 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images as numpy arrays\n",
    "np.save(\"../../np_imagedata/train_residual_pseudo_wnet_i_data_augmentation_compress_10_20_2019-03-25-pretrained.npy\",img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = '/home/ubuntu/volume1/TIFF/Testing_dct_unet'\n",
    "for ii in range(len(test_images)):\n",
    "    name = test_images[ii].split(\"/\")[-1]\n",
    "    path = os.path.join(out_path,name)\n",
    "    imsave(path,img_pred[ii,:,:,0])\n",
    "    \n",
    "# out_path = '/home/ubuntu/volume1/TIFF/Development_dct_unet/Validation'\n",
    "# for ii in range(len(test_images)):\n",
    "#     name = test_images[ii].split(\"/\")[-1]\n",
    "#     path = os.path.join(out_path,name)\n",
    "#     imsave(path,img_pred[ii,:,:,0])\n",
    "    \n",
    "# out_path = '/home/ubuntu/volume1/Gray_unet'\n",
    "# for ii in range(len(test_images)):\n",
    "#     name = test_images[ii].split(\"/\")[-1]\n",
    "#     path = os.path.join(out_path,name)\n",
    "#     imsave(path,img_pred[ii,:,:,0])\n",
    "    \n",
    "#     im = Image.fromarray(img_pred[ii,:,:,0])\n",
    "#     im.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_image = glob.glob('/home/ubuntu/volume1/TIFF/Testing_dct_unet/*.tif')\n",
    "num = 40\n",
    "testimg = Image.open(see_image[num])\n",
    "uncimg = Image.open(test_images[num])\n",
    "\n",
    "buf = io.BytesIO()\n",
    "uncimg.save(buf, \"JPEG\", quality=int(10))\n",
    "jpegimg = Image.open(buf)\n",
    "    \n",
    "plt.figure(figsize=(18,9))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(np.array(uncimg), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Uncompressed\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(np.array(jpegimg), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"JPEG Decompression\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(np.array(testimg), cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"U-Net Decompression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
